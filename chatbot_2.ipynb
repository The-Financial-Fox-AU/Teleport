{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot_2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/The-Financial-Fox-AU/Teleport/blob/master/chatbot_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLmiespSMXoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Description: MARCO the Chatbot for Virtual Experiences \n",
        "# Using nltk \n",
        "# No AI Implementation yet, although training data readily available \n",
        "# Training data: 'intents.json' file\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTwj2PZ5MjQP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "import nltk\n",
        "import random\n",
        "import json\n",
        "\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "\n",
        "stemmer = LancasterStemmer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-4pD19IRknr",
        "colab_type": "code",
        "outputId": "de05f4d1-1d61-4853-cc4d-4b37b03fd6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP0NfO6JPvw7",
        "colab_type": "code",
        "outputId": "617a246a-4ada-4b97-ca7a-58ce94c4b2af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "pip install tensorflow==1.13.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.13.2 in /usr/local/lib/python3.6/dist-packages (1.13.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.9.0)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.13.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.13.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.18.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.27.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.34.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.2) (46.0.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.2) (4.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.2) (2.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTarGu91QHAr",
        "colab_type": "code",
        "outputId": "892add0a-3bb6-4405-bf89-994f83ebf38c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "import tflearn\n",
        "import tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4gb62t7QvV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fvc4on-Q77w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('intents.json') as file:\n",
        "    data = json.load(file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Sp_XY5MxHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "labels = []\n",
        "doc_x = []\n",
        "doc_y = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvBERpIIMxRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        words.extend(w)\n",
        "        doc_x.append(w)\n",
        "        doc_y.append(intent['tag'])\n",
        "\n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXyOyzPTMxYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = [stemmer.stem(each.lower()) for each in words if each != '?']\n",
        "words = sorted(list(set(words)))\n",
        "labels = sorted(labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-lHGs_5Mxaz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training = []\n",
        "output = []\n",
        "\n",
        "out_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "for x,doc in enumerate(doc_x):\n",
        "    bag = []\n",
        "\n",
        "    w = [stemmer.stem(each) for each in doc]\n",
        "\n",
        "    for each in words:\n",
        "        if each in w:\n",
        "            bag.append(1)\n",
        "        else:\n",
        "            bag.append(0)\n",
        "\n",
        "    output_row = out_empty[:]\n",
        "    output_row[labels.index(doc_y[x])] = 1\n",
        "\n",
        "    training.append(bag)\n",
        "    output.append(output_row)\n",
        "\n",
        "training = numpy.array(training)\n",
        "output = numpy.array(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktc-KDH3NBw7",
        "colab_type": "code",
        "outputId": "74daae3b-7a26-4275-e234-4a52fad52a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "print(training)\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "[[0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLtzJIFwRMa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorflow.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI4jU9F4Wshx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK9l96HKUZm4",
        "colab_type": "code",
        "outputId": "82d1dc05-2b78-413f-9ac1-dc9012fcc1c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "tensorflow.reset_default_graph()\n",
        "net = tflearn.input_data(shape = [None, len(training[0])])\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, len(output[0]), activation = \"softmax\")\n",
        "net = tflearn.regression(net)\n",
        "\n",
        "model = tflearn.DNN(net)\n",
        "\n",
        "model.fit(training, output, n_epoch=500, batch_size = 8, show_metric = True)\n",
        "model.save(\"model.tflearn\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 2999  | total loss: \u001b[1m\u001b[32m0.09959\u001b[0m\u001b[0m | time: 0.017s\n",
            "| Adam | epoch: 500 | loss: 0.09959 - acc: 1.0000 -- iter: 40/44\n",
            "Training Step: 3000  | total loss: \u001b[1m\u001b[32m0.10013\u001b[0m\u001b[0m | time: 0.021s\n",
            "| Adam | epoch: 500 | loss: 0.10013 - acc: 1.0000 -- iter: 44/44\n",
            "--\n",
            "INFO:tensorflow:/content/model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P91gCce-XNMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bag_of_words(s, words):\n",
        "  bag = [0 for _ in range(len(words))]\n",
        "  s_words = nltk.word_tokenize(s)\n",
        "  s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "\n",
        "  for ea in s_words:\n",
        "    for i,w in enumerate(words):\n",
        "      if w == ea:\n",
        "        bag[i] = 1\n",
        "\n",
        "  return numpy.array(bag) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGC_youceED9",
        "colab_type": "code",
        "outputId": "751574f1-1418-4ac3-97e7-c33569ecee8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "def chat():\n",
        "  print('MARCO: Welcome to smart chat!')\n",
        "  while True:\n",
        "    user_response = input(\"YOU: \")\n",
        "    if user_response.lower() == 'quit':\n",
        "      break\n",
        "    else:\n",
        "      results = model.predict([bag_of_words(user_response, words)])\n",
        "      results_index = numpy.argmax(results)\n",
        "      tag = labels[results_index]\n",
        "      for x in data['intents']:\n",
        "        if x['tag'] == tag:\n",
        "          responses = x['responses']\n",
        "      print(random.choice(responses))\n",
        "chat()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MARCO: Welcome to smart chat!\n",
            "YOU: hello\n",
            "Good to see you again!\n",
            "YOU: hey\n",
            "Good to see you again!\n",
            "YOU: hey\n",
            "Hi there, how can I help?\n",
            "YOU: fitness\n",
            "Good to see you again!\n",
            "YOU: workout\n",
            "Here are some live fitness programs for you\n",
            "YOU: Can you suggest some good cooking classes\n",
            "You can try out these cooking sessions\n",
            "YOU: quit\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}